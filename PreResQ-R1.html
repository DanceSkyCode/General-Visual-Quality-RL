<!DOCTYPE html>

<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style></style>
  
  <meta name="description" content="ğŸ‘€âœ¨ğŸ–¼ï¸PreResQ-R1: Towards Fine-Grained Rank-and-Score Reinforcement Learning for Image Quality Assessment via Preference-Response Disentangled Policy Optimization">
  <meta name="keywords" content="reinforcement learning; ">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Bratrix</title>


  <link rel="shortcut icon" href="https://th.bing.com/th/id/ODL.0935e1a9966be0081df28fa6a466c91e?w=100&h=100&c=12&pcl=faf9f7&o=6&dpr=1.2&pid=AlgoBlockDebug" type="image/x-icon">
  <link href="./static/css" rel="stylesheet">

  <link rel="stylesheet" href="./static/bulma.min.css">
  <link rel="stylesheet" href="./static/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/academicons.min.css">
  <link rel="stylesheet" href="./static/index.css">
  <link rel="stylesheet" href="./static/leaderboard.css">

  <script type="text/javascript" src="./static/sort-table.js" defer=""></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer="" src="./static/fontawesome.all.min.js"></script>
  <script src="./static/bulma-carousel.min.js"></script>
  <script src="./static/bulma-slider.min.js"></script>
  <script src="./static/explorer-index.js"></script>
  <script src="./static/question_card.js"></script>

  <script src="./static/leaderboard_testmini.js"></script>  
  <script src="./static/output_folders.js" defer=""></script>
  <script src="./static/model_scores.js" defer=""></script>

  <script src="./static/data_public.js" defer=""></script>

  <style>
      #animated-bg {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        z-index: -1; /* æ”¾åˆ°é¡µé¢å†…å®¹åé¢ */
        background: #f0f4f8; /* æµ…ç°è“è‰²èƒŒæ™¯ï¼Œå¯æ¢æˆä½ å–œæ¬¢çš„æµ…è‰² */
      }
      .center-container {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100%;
            margin-top: -20px;
        }
    .node {
      fill: #f8f1e4;
      stroke: #000;
      stroke-width: 1;
      rx: 10;
      ry: 10;
    }
    .node text {
      font-size: 14px;
      text-anchor: middle;
    }
    .link {
      fill: none;
      stroke: #000;
      stroke-width: 2;
    }
    .badge {
      font-size: 12px;
    }
  </style>

</head>
<body>
<canvas id="animated-bg"></canvas>
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold" style="display: inline-block; margin-right: 0px;">
            <span style="vertical-align: middle">ğŸ‘€âœ¨ğŸ–¼ï¸PreResQ-R1: Towards Fine-Grained Rank-and-Score Reinforcement Learning for Image Quality Assessment via Preference-Response Disentangled Policy Optimization</span>
            </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=3G2NKeIAAAAJ&hl=zh-CN"><b>Zehui Feng</b></a><sup>1</sup>,</span>
              <span class="author-block">
            <br>  
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=sg4vxPoAAAAJ&hl=en"><b>Tian Qiu</b></a><sup>1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=sg4vxPoAAAAJ&hl=en"><b>Tong Wu</b></a><sup>1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=sg4vxPoAAAAJ&hl=en"><b>Huayuan Xu</b></a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.scopus.com/authid/detail.uri?authorId=55425962400"><b>Ting Han</b></a><sup>1,3</sup><sup>â€ </sup></span>
            
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block" style="margin-right: 15px;"><sup>1</sup>Shanghai Jiao Tong University,</span> 
            <span class="author-block" style="margin-right: 15px;"><sup>2</sup>Zhejiang University,</span>
            <span class="paper-block"><sup>â€ </sup>Corresponding Author,  Under Review</b></span>
          </div>
<!--           <span class=""><sup>*</sup>Equal Contribution</span>
          <span class=""><sup>â€ </sup>Corresponding Authors</span> -->
          
        
          <!-- ArXiv Link. -->
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://github.com/DanceSkyCode/General-Visual-Quality-RL" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/DanceSkyCode/General-Visual-Quality-RL" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/DanceSkyCode/PreResIQA-R1" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">ğŸ¤—</p>
                      <!-- ğŸ”— -->
                  </span>
                  <span>Checkpoints</span>
                </a>
              </span> 
                </a>
              </span> 

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Begin Teaser -->
<div>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="content has-text-centered">
      <img src="statics/Overall.png" alt="data-overview">
    </div>
    <div class="hero-body">
      <h2 class="subtitle has-text-justified">
        <p class="has-text-left">
          <b>Overall Performance.</b><br>
          (a) Existing score/ranking reward function assign minimal difference, which results in distribution fall or robustness fail. <br>
          (b) PreResQ-R1 focus on fine-grained response-ranking reward balance and preference. <br>
          (c) PreResQ-R1 enables state-of-the-art performance and stable image quality assessment with discriminative reward.<br>
          (d) typical qualitative and quantitative example comparison between VisualQuality-R1 and PreResQ-R1, which demonstrates superior performance on image quality describe and score.
        </p>
      </h2>
    </div>
  </div>
</section>


</div>
<!-- End Teaser -->

<section class="section">
  <div class="container is-max-desktop" >
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
            <p>
              Visual Quality Assessment (QA) seeks to predict human perceptual judgments of visual fidelity. While recent multimodal large language models (MLLMs) show promise in reasoning about image and video quality, existing approaches mainly rely on supervised fine-tuning or rank-only objectives, resulting in shallow reasoning, poor score calibration, and limited cross-domain generalization. We propose PreResQ-R1, a Preferenceâ€“Response Disentangled Reinforcement Learning framework that unifies absolute score regression and relative ranking consistency within a single reasoning-driven optimization scheme. Unlike prior QA methods, PreResQ-R1 introduces a dual-branch reward formulation that separately models intra-sample response coherence and inter-sample preference alignment, optimized via Group Relative Policy Optimization (GRPO). This design encourages fine-grained, stable, and interpretable chain-of-thought reasoning about perceptual quality. To extend beyond static imagery, we further design a globalâ€“temporal and localâ€“spatial data flow strategy for Video Quality Assessment. Remarkably, with reinforcement fine-tuning on only 6K images and 28K videos, PreResQ-R1 achieves state-of-the-art results across 10 IQA and 5 VQA benchmarks under both PLCC and SRCC metrics. Beyond quantitative gains, it produces human-aligned reasoning traces that reveal the perceptual cues underlying quality judgments. Code and model are available.
            </p>
        </div>

      </div>
    </div>
  </div>

    <!--/ Abstract. -->


<section class="section">
  <div class="container is-max-desktop" >
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method Overview</h2>


      </div>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-centered" style="margin-top: 1cm;">
        <img src="./static/images/Bratrix.png" alt="pipeline" >
      </div>
    </div>
    
    <div class="hero-body">
      <h2 class="has-text-justified" style="margin-top: -1cm;">
        <p class="">ğŸŒŸğŸŒŸğŸŒŸ Overall Framework of Bratrix. Bratrix comprises Vision semantic decoupling pipeline, a Brain encoder pipeline, a language semantic decoupling pipeline, and a language-anchored visual-brain alignment. <br>
          ğŸŒŸğŸŒŸğŸŒŸ There are totally four stages in this framework: single-modal per-training phase, multi-modal fine-tuning phase, inference phase, and downstream task phase. </p>
      </h2>
    </div>
    
  </div>
  </div>



</section>


<section class="section">
  <div class="container is-max-desktop" >
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Bratrix and Bratrix-M Explainable Visualization</h2>


      </div>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-centered" style="margin-top: 1cm; max-width: 90%;">
        <img src="./static/images/Image_T-SNE.png" alt="pipeline" >
      </div>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-centered" style="margin-top: 1cm; max-width: 90%;">
        <img src="./static/images/Image_Explain.png" alt="pipeline" >
      </div>
    </div>
    <div class="hero-body">
      <h2 class="subtitle has-text-justified" style="margin-top: -1cm;">
        
      </h2>
    </div>
    
  </div>
  </div>

</section>


<section class="section">
  <div class="container is-max-desktop" >
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Bratrix and Bratrix-M Quantitative Comparison and Ablation</h2>


      </div>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-centered" style="margin-top: 1cm; max-width: 90%;">
        <img src="./static/images/Table-comparison.png" alt="pipeline" >
      </div>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-centered" style="margin-top: 1cm; max-width: 90%;">
        <img src="./static/images/Table_abltion.png" alt="pipeline" >
      </div>
    </div>
    <div class="hero-body">
      <h2 class="subtitle has-text-justified" style="margin-top: -1cm;">
        
      </h2>
    </div>
    
  </div>
  </div>

</section>

<section class="section">
  <div class="container is-max-desktop" >
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Bratrix Image Retrieval Results</h2>


      </div>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-centered" style="margin-top: 1cm; max-width: 90%;">
        <img src="./static/images/Image_retrieval.png" alt="pipeline" >
      </div>
    </div>
    <div class="hero-body">
      <h2 class="subtitle has-text-justified" style="margin-top: -1cm;">
        
      </h2>
    </div>
    
  </div>
  </div>

</section>


<section class="section">
  <div class="container is-max-desktop" >
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Bratrix Image Reconstruction Results</h2>

      </div>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-centered" style="margin-top: 1cm;">
        <img src="./static/images/Image_reconstrcution.png" alt="pipeline" >
      </div>
    </div>
    
    <div class="hero-body">
    </div>
    
  </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop" >
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Bratrix Image Caption Results</h2>

      </div>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-centered" style="margin-top: 1cm;">
        <img src="./static/images/Image_cpation.png" alt="pipeline" >
      </div>
    </div>
    
    <div class="hero-body">
    </div>
    
  </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop" >
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Bratrix Bratrix-M Performance in MEG and fMRI modalities</h2>

      </div>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-centered" style="margin-top: 1cm;">
        <img src="./static/images/Image_MEG_fMRI.png" alt="pipeline" >
      </div>
    </div>
    
    <div class="hero-body">
    </div>
    
  </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop" >
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Detail Results in Comparison and Ablation</h2>

      </div>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-centered" style="margin-top: 1cm;">
        <img src="./static/images/Table_detail1.png" alt="pipeline" >
      </div>
    </div>
        <div class="columns is-centered">
      <div class="content has-text-centered" style="margin-top: 1cm;">
        <img src="./static/images/Table_detail2.png" alt="pipeline" >
      </div>
    </div>
    <div class="hero-body">
    </div>
    
  </div>
  </div>
</section>
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>

@article{Bratrix,
  title={PreResQ-R1: Towards Fine-Grained Rank-and-Score Reinforcement Learning for Image Quality Assessment via Preferenceâ€“Response Disentangled Policy Optimization},
  author={Zehui Feng, Tian Qiu, Tong Wu, Huayuan Xu, Ting Han},
  journal={arXiv preprint arXiv:},
  year={2025}
}

    </code></pre>
  </div>
</section>
<script>
const canvas = document.getElementById('animated-bg');
const ctx = canvas.getContext('2d');
canvas.width = window.innerWidth;
canvas.height = window.innerHeight;

const particles = [];
const particleCount = 80;

for(let i = 0; i < particleCount; i++) {
    particles.push({
        x: Math.random() * canvas.width,
        y: Math.random() * canvas.height,
        r: Math.random() * 3 + 1,
        dx: (Math.random() - 0.5) * 0.5,
        dy: (Math.random() - 0.5) * 0.5
    });
}

function animate() {

    ctx.fillStyle = '#f0f4f8'; 
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    for(let p of particles) {
        ctx.beginPath();
        ctx.arc(p.x, p.y, p.r, 0, Math.PI * 2);
        ctx.fillStyle = 'rgba(50,50,50,0.5)'; 
        ctx.fill();
        p.x += p.dx;
        p.y += p.dy;
        if(p.x < 0 || p.x > canvas.width) p.dx *= -1;
        if(p.y < 0 || p.y > canvas.height) p.dy *= -1;
    }
    requestAnimationFrame(animate);
}
animate();
window.addEventListener('resize', () => {
    canvas.width = window.innerWidth;
    canvas.height = window.innerHeight;
});
</script>
</body></html>
